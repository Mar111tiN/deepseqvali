rule detect_VAFs:
    input: 
        bam = "recalib/{sample}.bam",
        bai = "recalib/{sample}.bai"
    output:
        vafs = "vaf/{sample}.csv"
    params: 
        bed_file = get_snp_bedfile(folder='bed', mut_df=mut_df), # writes bedfile,
        cleanSNP = os.path.join(snakedir, "scripts/shell/cleanSNP.mawk"),
        snpVAF = os.path.join(snakedir, "scripts/shell/snpVAF.mawk"),
        minVAF = config['VAFdetect']['minVAF'],
        ref = full_path('genome'),
        qual = f"-q {config['VAFdetect']['MAPQ']} -Q {config['VAFdetect']['Q']}",
        ff = f"--ff UNMAP,SECONDARY,QCFAIL{config['VAFdetect']['remove_dups'] * ',DUP'}{' -x' if config['VAFdetect']['include_overlaps'] else ''}"
    conda:
        f"../{config['envs']}/align-env.yml"
    threads:
        config['VAFdetect']['threads']
    shell:
        "samtools mpileup {params.ff} {params.qual} -f {params.ref} -l {params.bed_file} {input.bam} | "
        "{params.cleanSNP} | {params.snpVAF} {params.minVAF} > {output.vafs}"


rule combine:
    input:
        vafs = expand("vaf/{sample}.csv", sample=sample_df.index)
    output: "results.txt"
    threads: 1
    run:
        dfs = []

        base_cols = ['sample', 'Chr', 'Start']
        out_cols = ['sample', 'MutID', 'Chr', 'Start', 'End', 'Ref', 'Alt', 'calledAlt', 'VAF', 'Depth']

        for vaf_file in input.vafs:
            # extract the sample name from vaf file
            sample = vaf_file.split('/')[1].replace('.csv', '')
            # load the file and rename Alt
            df = pd.read_csv(vaf_file, sep='\t').rename(dict(Alt='calledAlt'), axis=1)
            df.loc[:, 'sample'] = sample
            dfs.append(df)
        vaf_df = pd.concat(dfs)
        # merge into mut_df and write to file
        result_df = mut_df.drop('Ref', axis=1).merge(vaf_df, on=base_cols, how='left')
        # make Chr column categorical for sorting .. and sort
        chrom_list = [f"chr{i}" for i in range(23)] + ['chrX', 'chrY']
        result_df['Chr'] = pd.Categorical(result_df['Chr'], chrom_list)
        result_df = result_df.sort_values(base_cols).loc[:, out_cols]

        for col in out_cols[-3:]:
            result_df.loc[:, col] = result_df[col].fillna(-1)
        show_output(f'Writing combined results to {str(output)}', color='success')
        result_df.to_csv(str(output), index=False, sep='\t')
        

rule IGV_nav:
    input:
        bam = "recalib/{sample}.bam"
    output:
        IGVnav = "IGVnav/{sample}.txt"
    threads: 1
    run:
        sample = wildcards.sample
        df = mut_df.query('sample == @sample').loc[:, ['Chr', 'Start', 'End', 'Ref', 'Alt']]
        for col in ['Call', 'Tags', 'Notes']:
            df[col] = ''
        df.loc[:, 'Chr'] = df['Chr'].str.replace('chr', '')
        df.to_csv(str(output), sep='\t', index=False)
        show_output(f"Written to {output.IGVnav}")